{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "ここでは、torchtextを使う代わりにHugging Faceが提供しているライブラリを用いて、感情分析タスクを行います。現在、torchtextのFieldクラスは非推奨となっており、最新バージョンでは使えないそうです。また、torchtext自体もこれ以上アップグレードされないそうですので、別のライブラリを使う必要があるかと存じます。なお、359ページ以降のみを実装していきます。"
      ],
      "metadata": {
        "id": "X9kPOOiqbUxk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 設定\n",
        "Google ColabとGoogle Driveを用いて実装していきます。"
      ],
      "metadata": {
        "id": "oYsuK07TEU7i"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2GLfrW7-D-h_"
      },
      "outputs": [],
      "source": [
        "# ディレクトリの設定\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "root_path = '/content/drive/My Drive/your/dir/path/7_nlp_sentiment_transformer'\n",
        "%cd $root_path"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ライブラリのインストール\n",
        "!pip install gensim          # fastTextを読み込むために使います\n",
        "!pip install datasets        # torchtextの代わりに使います\n",
        "# !pip install transformers  # 必要に応じてインストールしてください。Colabだとプレインストールされています"
      ],
      "metadata": {
        "id": "wrdJH8FWE3p3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 分散表現の準備\n",
        "ここでは分散表現をダウンロードします。単語ベクトルの扱いにはgensimライブラリを用います。"
      ],
      "metadata": {
        "id": "tW7w7nnpHN7f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 分散表現のダウンロード\n",
        "import gensim\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# file_path\n",
        "vec_file = root_path + '/data/wiki-news-300d-1M.vec'\n",
        "\n",
        "# gensimを使用して.vecファイルから単語ベクトルを読み込む\n",
        "model = gensim.models.KeyedVectors.load_word2vec_format(vec_file)\n",
        "\n",
        "# 単語ベクトルをPyTorchのテンソルに変換\n",
        "fasttext_model = torch.FloatTensor(model.vectors)"
      ],
      "metadata": {
        "id": "-78rGLhME9Oc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 分散表現の確認\n",
        "print('1単語を表現する次元数: ', fasttext_model.shape[1])\n",
        "print(\"単語数: \", fasttext_model.shape[0])\n",
        "\n",
        "print(fasttext_model[model.key_to_index['king']])\n",
        "\n",
        "print(fasttext_model.shape)\n",
        "\n",
        "print(model.key_to_index)"
      ],
      "metadata": {
        "id": "-5zs5BG7FiBY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 前処理等\n",
        "IMDb_train.tsv、IMDb_test.tsvをColab上で作成するとうまくいきませんでした。ローカルで作成したうえでDriveに保存することをお勧めします。\n",
        "\n",
        "また、書籍通りに.tsvファイルを作成するとうまくいきませんでした。具体的には、余計な列が含まれてしまうので、それらを削除する必要がありました。その場合はpandasライブラリを用いることで簡単に削除できます。\n",
        "\n",
        "以下の順番で実装していきます。\n",
        "\n",
        "-前処理\n",
        "\n",
        "-トークン化\n",
        "\n",
        "-DataLoaderの作成\n",
        "\n",
        "-ボキャブラリの作成"
      ],
      "metadata": {
        "id": "o8IfQnnvHW4e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 前処理、トークン化、DataLoaderの作成\n",
        "# AutoTokenizerを用いています\n",
        "# （たぶんもっと上手い実装の仕方があると思います。。。）\n",
        "\n",
        "from datasets import load_dataset, DatasetDict\n",
        "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
        "from torch.utils.data import DataLoader\n",
        "import re\n",
        "\n",
        "# 前処理とトークナイズを組み合わせた関数\n",
        "def preprocess_and_tokenize(examples):\n",
        "\n",
        "    # テキストの前処理\n",
        "    examples['text'] = [re.sub('', '', t) for t in examples['text']]\n",
        "    examples['text'] = [re.sub(r'[^.,a-zA-Z0-9\\s]', ' ', t) for t in examples['text']]\n",
        "    examples['text'] = [t.replace('.', ' . ').replace(',', ' , ') for t in examples['text']]\n",
        "\n",
        "    # トークナイズとラベルの追加\n",
        "    tokenized_inputs = tokenizer(examples['text'], padding='max_length', truncation=True, max_length=256)\n",
        "\n",
        "    # 'labels' キーを追加\n",
        "    tokenized_inputs['labels'] = examples['label']\n",
        "\n",
        "    # 'token_type_ids' が不要な場合は削除\n",
        "    if 'token_type_ids' in tokenized_inputs:\n",
        "        del tokenized_inputs['token_type_ids']\n",
        "    return tokenized_inputs\n",
        "\n",
        "# 事前学習済みモデルに対応する AutoTokenizer のロード\n",
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# データセットの読み込み\n",
        "tr_path = root_path + '/data/IMDb_train.tsv'   # Colab上で.tsvファイルを作成するとデータが欠損しました\n",
        "ts_path = root_path + '/data/IMDb_test.tsv'\n",
        "\n",
        "# データセットの読み込みと前処理\n",
        "tr_val_ds = load_dataset('csv', data_files=tr_path, delimiter='\\t', split='train', column_names=['text', 'label'])\n",
        "ts_ds = load_dataset('csv', data_files=ts_path, delimiter='\\t', split='train', column_names=['text', 'label'])\n",
        "\n",
        "# 前処理とトークナイズの適用\n",
        "tr_val_ds = tr_val_ds.map(preprocess_and_tokenize, batched=True)\n",
        "ts_ds = ts_ds.map(preprocess_and_tokenize, batched=True)\n",
        "\n",
        "# IDリストを作成\n",
        "id_to_word = {v: k for k, v in tokenizer.vocab.items()}\n",
        "\n",
        "# テキストとラベルのデータを保存\n",
        "Text = tr_val_ds['text']\n",
        "Label = tr_val_ds['label']\n",
        "Text_ts = ts_ds['text']\n",
        "Label_ts = ts_ds['label']\n",
        "\n",
        "# 不要な列の削除\n",
        "tr_val_ds = tr_val_ds.remove_columns(['text', 'label'])\n",
        "ts_ds = ts_ds.remove_columns(['text', 'label'])\n",
        "\n",
        "# DatasetDictを作成して分割\n",
        "dataset_dict = DatasetDict({\n",
        "    'train': tr_val_ds\n",
        "})\n",
        "train_test_split = dataset_dict['train'].train_test_split(test_size=0.2)\n",
        "\n",
        "# 分割されたデータセットを取得\n",
        "tr_ds = train_test_split['train']\n",
        "val_ds = train_test_split['test']\n",
        "\n",
        "# DataCollatorWithPadding のインスタンスを作成\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "tr_dl = DataLoader(tr_ds, shuffle=True, batch_size=8, collate_fn=data_collator)\n",
        "val_dl = DataLoader(val_ds, batch_size=8, collate_fn=data_collator)\n",
        "ts_dl = DataLoader(ts_ds, batch_size=8, collate_fn=data_collator)\n"
      ],
      "metadata": {
        "id": "2Q07FetHHV9D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 動作確認\n",
        "for batch in ts_dl:\n",
        "    input_ids = batch['input_ids']\n",
        "    attention_mask = batch['attention_mask']\n",
        "    labels = batch['labels']\n",
        "    print(\"Input IDs:\", input_ids)\n",
        "    print(\"Attention Mask:\", attention_mask)\n",
        "    print(\"Labels:\", labels)\n",
        "    break"
      ],
      "metadata": {
        "id": "kzh5lTGBLzMB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ボキャブラリの作成\n",
        "from collections import Counter\n",
        "from gensim.corpora import Dictionary\n",
        "\n",
        "word_counts = Counter()\n",
        "\n",
        "for example in tr_ds:\n",
        "  words = [id_to_word[token_id] for token_id in example['input_ids']]\n",
        "  word_counts.update(words)\n",
        "\n",
        "gensim_dictionary = Dictionary()\n",
        "\n",
        "for word in word_counts:\n",
        "  gensim_dictionary.add_documents([[word]])\n",
        "\n",
        "word_id = gensim_dictionary.token2id"
      ],
      "metadata": {
        "id": "-hJ3TY1YJTV3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Neural Networkの設計\n",
        "ここでは、データの取り出し方を使用しているライブラリに合わせて変更しています。また、現行のバージョンのPythonに合わせてコードを一部書き換えています。"
      ],
      "metadata": {
        "id": "xhwyxe1oTpg5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "xZmOeO_bUDwV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Embedder(nn.Module):\n",
        "  def __init__(self, text_embedding_vectors):\n",
        "    super().__init__()\n",
        "    self.embeddings = nn.Embedding.from_pretrained(embeddings=fasttext_model, freeze=True)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x_vec = self.embeddings(x)\n",
        "    return x_vec"
      ],
      "metadata": {
        "id": "N07apKa6UI5I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 動作確認\n",
        "batch = next(iter(tr_dl))\n",
        "\n",
        "net1 = Embedder(fasttext_model)\n",
        "x = batch['input_ids']\n",
        "x1 = net1(x)\n",
        "\n",
        "print('size of input tensor: ', x.shape)\n",
        "print('size of output tensor: ', x1.shape)"
      ],
      "metadata": {
        "id": "3WYP9H7YUQHi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEncoder(nn.Module):\n",
        "  def __init__(self, d_model=300, max_seq_len=256):\n",
        "    super().__init__()\n",
        "    self.d_model = d_model\n",
        "    pe = torch.zeros(max_seq_len, d_model)\n",
        "\n",
        "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "    pe = pe.to(device)\n",
        "\n",
        "    for pos in range(max_seq_len):\n",
        "      for i in range(0, d_model, 2):\n",
        "        pe[pos, i] = math.sin(pos / (10000 ** ((2 * i) / d_model)))\n",
        "        pe[pos, i + 1] = math.cos(pos / (10000 ** ((2 * i) / d_model)))\n",
        "\n",
        "    self.pe = pe.unsqueeze(0)\n",
        "    self.pe.requires_grad = False\n",
        "\n",
        "  def forward(self, x):\n",
        "    ret = math.sqrt(self.d_model) * x + self.pe\n",
        "    return ret"
      ],
      "metadata": {
        "id": "UwAB6AlxUjwc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 動作確認\n",
        "net1 = Embedder(fasttext_model)\n",
        "net2 = PositionalEncoder(d_model=300, max_seq_len=256)\n",
        "\n",
        "x = batch['input_ids']\n",
        "x1 = net1(x)\n",
        "x2 = net2(x1)\n",
        "\n",
        "print(\"size of input tensor: \", x1.shape)\n",
        "print(f\"size of output tensor: {x2.shape}\")"
      ],
      "metadata": {
        "id": "vzEGcSWoUvPe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Attention(nn.Module):\n",
        "  def __init__(self, d_model=300):\n",
        "    super().__init__()\n",
        "    self.q_linear = nn.Linear(d_model, d_model)\n",
        "    self.v_linear = nn.Linear(d_model, d_model)\n",
        "    self.k_linear = nn.Linear(d_model, d_model)\n",
        "\n",
        "    self.out = nn.Linear(d_model, d_model)\n",
        "    self.d_k = d_model   # Attentionの大きさ調整の変数\n",
        "\n",
        "  def forward(self, q, k, v, mask):\n",
        "    k = self.k_linear(k)\n",
        "    q = self.q_linear(q)\n",
        "    v = self.v_linear(v)\n",
        "\n",
        "    weights = torch.matmul(q, k.transpose(1, 2) / math.sqrt(self.d_k))\n",
        "\n",
        "    mask = mask.unsqueeze(1)\n",
        "    weights = weights.masked_fill(mask == 0, -1e9)\n",
        "\n",
        "    normalized_weights = F.softmax(weights, dim=-1)\n",
        "    output = torch.matmul(normalized_weights, v)\n",
        "    output = self.out(output)\n",
        "\n",
        "    return output, normalized_weights"
      ],
      "metadata": {
        "id": "w-yMocZHU2Oj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedForward(nn.Module):\n",
        "  def __init__(self, d_model, d_ff=1024, dropout=0.1):\n",
        "    super().__init__()\n",
        "    self.linear_1 = nn.Linear(d_model, d_ff)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    self.linear_2 = nn.Linear(d_ff, d_model)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.linear_1(x)\n",
        "    x = self.dropout(x)\n",
        "    x = self.linear_2(x)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "RSkv6fZgVCwd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "  def __init__(self, d_model, dropout=0.1):\n",
        "    super().__init__()\n",
        "    self.norm_1 = nn.LayerNorm(d_model)\n",
        "    self.norm_2 = nn.LayerNorm(d_model)\n",
        "    self.attn   = Attention(d_model)\n",
        "    self.ff     = FeedForward(d_model)\n",
        "    self.dropout_1 = nn.Dropout(dropout)\n",
        "    self.dropout_2 = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self, x, mask):\n",
        "    x_normalized = self.norm_1(x)\n",
        "    output, normalized_weights = self.attn(x_normalized, x_normalized, x_normalized, mask)\n",
        "\n",
        "    x2 = x + self.dropout_1(output)\n",
        "    x_normalized_2 = self.norm_2(x2)\n",
        "    output = x2 + self.dropout_2(self.ff(x_normalized_2))\n",
        "\n",
        "    return output, normalized_weights"
      ],
      "metadata": {
        "id": "UADc7UQsVKzv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 動作確認\n",
        "net1 = Embedder(fasttext_model)\n",
        "net2 = PositionalEncoder(d_model=300, max_seq_len=256)\n",
        "net3 = TransformerBlock(d_model=300)\n",
        "\n",
        "x = batch['input_ids']\n",
        "input_pad = 91                 # [PAD]のIDに注意\n",
        "input_mask = (x != input_pad)\n",
        "print(input_mask)\n",
        "\n",
        "x1 = net1(x)\n",
        "x2 = net2(x1)\n",
        "x3, normalized_weights = net3(x2, input_mask)\n",
        "\n",
        "print(f\"size of input tensor: {x1.shape}\")\n",
        "print(f\"size of output tensor: {x3.shape}\")\n",
        "print(f\"size of Attention; {normalized_weights.shape}\")"
      ],
      "metadata": {
        "id": "ZehCEX7GVany"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Classification(nn.Module):\n",
        "  def __init__(self, d_model, output_dim=2):\n",
        "    super().__init__()\n",
        "    self.linear = nn.Linear(d_model, output_dim)\n",
        "    nn.init.normal_(self.linear.weight, std=0.02)\n",
        "    nn.init.normal_(self.linear.bias, 0)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x0 = x[:, 0, :]\n",
        "    out = self.linear(x0)\n",
        "\n",
        "    return out"
      ],
      "metadata": {
        "id": "5GmYD6b6VqF7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerClassification(nn.Module):\n",
        "  def __init__(self, text_embedding_vectors, d_model=300, max_seq_len=256, output_dim=2):\n",
        "    super().__init__()\n",
        "\n",
        "    self.net1 = Embedder(fasttext_model)\n",
        "    self.net2 = PositionalEncoder(d_model=d_model, max_seq_len=max_seq_len)\n",
        "    self.net3_1 = TransformerBlock(d_model=d_model)\n",
        "    self.net3_2 = TransformerBlock(d_model=d_model)\n",
        "    self.net4 = Classification(output_dim=output_dim, d_model=d_model)\n",
        "\n",
        "  def forward(self, x, mask):\n",
        "    x1 = self.net1(x)\n",
        "    x2 = self.net2(x1)\n",
        "    x3_1, normalized_weights_1 = self.net3_1(x2, mask)\n",
        "    x3_2, normalized_weights_2 = self.net3_2(x3_1, mask)\n",
        "    x4 = self.net4(x3_2)\n",
        "\n",
        "    return x4, normalized_weights_1, normalized_weights_2\n",
        "\n"
      ],
      "metadata": {
        "id": "BDGFuFw3VwNy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 動作確認\n",
        "\n",
        "batch = next(iter(tr_dl))\n",
        "\n",
        "net = TransformerClassification(\n",
        "    text_embedding_vectors=fasttext_model,\n",
        "    d_model=300,\n",
        "    max_seq_len=256,\n",
        "    output_dim=2\n",
        ")\n",
        "\n",
        "x = batch['input_ids']\n",
        "input_pad = 91\n",
        "input_mask = (x != input_pad)\n",
        "out, normalized_attention_weights_1, normalized_attention_weights_2 = net(x, input_mask)\n",
        "\n",
        "print(f\"size of output tensor: {out.shape}\")\n",
        "print(f\"output of sigmoid function: {F.softmax(out)}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "KIhWvaooV_HS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transformerモデルの学習と評価\n",
        "ここも、上と同じくデータの取り出し方を変更しています。"
      ],
      "metadata": {
        "id": "krvJNsMLi3x2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Networkの初期化\n",
        "\n",
        "# 学習・検証データの準備\n",
        "dl_dict = {'train': tr_dl, 'val': val_dl}\n",
        "\n",
        "# model構築\n",
        "net = TransformerClassification(\n",
        "    text_embedding_vectors=fasttext_model,\n",
        "    d_model=300,\n",
        "    max_seq_len=256,\n",
        "    output_dim=2\n",
        ")\n",
        "\n",
        "# initialization\n",
        "def weights_init(m):\n",
        "  classname = m.__class__.__name__\n",
        "  if classname.find('Linear') != -1:\n",
        "    nn.init.kaiming_normal_(m.weight)\n",
        "    if m.bias is not None:\n",
        "      nn.init.constant_(m.bias, 0.0)\n",
        "\n",
        "net.train()\n",
        "\n",
        "net.net3_1.apply(weights_init)\n",
        "net.net3_2.apply(weights_init)\n",
        "\n",
        "print('Network initialized !!')\n"
      ],
      "metadata": {
        "id": "gkRue50-WZw7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ハイパーパラメータの設定\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "LR = 2e-5\n",
        "optimizer = optim.Adam(net.parameters(), lr=LR)"
      ],
      "metadata": {
        "id": "PvQMdQCZWpIh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def train_model(net, dl_dict, criterion, optimizer, num_epochs):\n",
        "  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "  compute_device = \"GPU\" if device.type == \"cuda\" else \"CPU\"\n",
        "  print(f\"This is {compute_device} trainer !!\")\n",
        "  print(\"-\"*20, \"Start\", \"-\"*20)\n",
        "\n",
        "  net.to(device)\n",
        "\n",
        "  # network acceleration\n",
        "  torch.backends.cudnn.benchmark = True\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "    for phase in ['train', 'val']:\n",
        "      if phase == 'train':\n",
        "        net.train()\n",
        "      else:\n",
        "        net.eval()\n",
        "\n",
        "      epoch_loss = 0.0\n",
        "      epoch_corrects = 0\n",
        "\n",
        "      for batch in tqdm(dl_dict[phase]):\n",
        "        inputs = batch['input_ids'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        with torch.set_grad_enabled(phase == 'train'):\n",
        "          # mask\n",
        "          input_pad = 91\n",
        "          input_mask = (inputs != input_pad)\n",
        "\n",
        "          # to transformzer\n",
        "          outputs, _, _ = net(inputs, input_mask)\n",
        "          loss = criterion(outputs, labels)\n",
        "          _, preds = torch.max(outputs, 1)\n",
        "\n",
        "          if phase == 'train':\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "          epoch_loss += loss.item() * inputs.size(0)\n",
        "          epoch_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "      epoch_loss = epoch_loss / len(dl_dict[phase].dataset)\n",
        "      epoch_acc  = epoch_corrects.double() / len(dl_dict[phase].dataset)\n",
        "\n",
        "      print('Epoch {}/{} | {:^5} | Loss: {:.4f} ACC: {:.4f}'.format(\n",
        "          epoch + 1,\n",
        "          num_epochs,\n",
        "          phase,\n",
        "          epoch_loss,\n",
        "          epoch_acc\n",
        "      ))\n",
        "\n",
        "  return net\n",
        "\n"
      ],
      "metadata": {
        "id": "JHeqLxcfWzy5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習\n",
        "num_epochs = 2\n",
        "net_trained = train_model(net, dl_dict, criterion, optimizer, num_epochs=num_epochs)"
      ],
      "metadata": {
        "id": "T-HI9WAVW4Gh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#評価\n",
        "device = torch.device(\"cuda0\" if torch.cuda.is_available() else \"cpu\")\n",
        "net_trained.eval()\n",
        "net_trained.to(device)\n",
        "\n",
        "epoch_corrects = 0\n",
        "for batch in ts_dl:\n",
        "  inputs = batch['input_ids'].to(device)\n",
        "  labels = batch['labels'].to(device)\n",
        "\n",
        "  with torch.set_grad_enabled(False):\n",
        "    input_pad = 91\n",
        "    input_mask = (inputs != input_pad)\n",
        "\n",
        "    outputs, _, _ = net_trained(inputs, input_mask)\n",
        "    _, preds = torch.max(outputs, 1)\n",
        "    epoch_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "epoch_acc = epoch_corrects.double() / len(ts_ds)\n",
        "print('ACC with {} test data: {:.4f}'.format(len(ts_dl.dataset), epoch_acc))"
      ],
      "metadata": {
        "id": "GLRzE_XBXA6y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epoch_acc = epoch_corrects.double() / len(ts_ds)\n",
        "print('ACC with {} test data: {:.4f}'.format(len(ts_dl.dataset), epoch_acc))"
      ],
      "metadata": {
        "id": "YA7td13F5Aw1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Attentionの可視化\n",
        "ここもデータの取り出し方を変更しています。"
      ],
      "metadata": {
        "id": "VNTnY6nYLpBg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# HTMLを作成する関数を実装\n",
        "\n",
        "def highlight(word, attn):\n",
        "    \"Attentionの値が大きいと文字の背景が濃い赤になるhtmlを出力させる関数\"\n",
        "\n",
        "    html_color = '#%02X%02X%02X' % (\n",
        "        255, int(255*(1 - attn)), int(255*(1 - attn)))\n",
        "    return '<span style=\"background-color: {}\"> {}</span>'.format(html_color, word)\n",
        "\n",
        "\n",
        "def mk_html(index, ts_ds, preds, normlized_weights_1, normlized_weights_2):\n",
        "    \"HTMLデータを作成する\"\n",
        "\n",
        "    # indexの結果を抽出\n",
        "    example  = ts_ds[index]  # データセットからサンプルを取得\n",
        "    sentence = tokenizer.convert_ids_to_tokens(example['input_ids'])  # 文章\n",
        "    label    = example['labels']  # ラベル\n",
        "    pred     = preds[index]  # 予測\n",
        "\n",
        "    # indexのAttentionを抽出と規格化\n",
        "    attens1 = normlized_weights_1[index, 0, :]  # 0番目の<cls>のAttention\n",
        "    attens1 /= attens1.max()\n",
        "\n",
        "    attens2 = normlized_weights_2[index, 0, :]  # 0番目の<cls>のAttention\n",
        "    attens2 /= attens2.max()\n",
        "\n",
        "    # ラベルと予測結果を文字に置き換え\n",
        "    if label == 0:\n",
        "        label_str = \"Negative\"\n",
        "    else:\n",
        "        label_str = \"Positive\"\n",
        "\n",
        "    if pred == 0:\n",
        "        pred_str = \"Negative\"\n",
        "    else:\n",
        "        pred_str = \"Positive\"\n",
        "\n",
        "    # 表示用のHTMLを作成する\n",
        "    html = '正解ラベル：{}<br>推論ラベル：{}<br><br>'.format(label_str, pred_str)\n",
        "\n",
        "    # 1段目のAttention\n",
        "    html += '[TransformerBlockの1段目のAttentionを可視化]<br>'\n",
        "    for word_id, attn in zip(example['input_ids'], attens1):\n",
        "        word = tokenizer.convert_ids_to_tokens([word_id])[0]\n",
        "        html += highlight(word, attn)\n",
        "    html += \"<br><br>\"\n",
        "\n",
        "    # 2段目のAttention\n",
        "    html += '[TransformerBlockの1段目のAttentionを可視化]<br>'\n",
        "    for word_id, attn in zip(example['input_ids'], attens2):\n",
        "        word = tokenizer.convert_ids_to_tokens([word_id])[0]\n",
        "        html += highlight(word, attn)\n",
        "    html += \"<br><br>\"\n",
        "\n",
        "    return html"
      ],
      "metadata": {
        "id": "C2xlr81gOIbV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import HTML\n",
        "\n",
        "# Transformerで処理\n",
        "\n",
        "# ミニバッチの用意\n",
        "batch = next(iter(ts_dl))\n",
        "\n",
        "# GPUが使えるならGPUにデータを送る\n",
        "inputs = batch['input_ids'].to(device)  # 文章\n",
        "labels = batch['labels'].to(device)  # ラベル\n",
        "\n",
        "# mask作成\n",
        "input_pad = 91  # 単語のIDにおいて、'<pad>': 1 なので\n",
        "input_mask = (inputs != input_pad)\n",
        "\n",
        "# Transformerに入力\n",
        "outputs, normlized_weights_1, normlized_weights_2 = net_trained(\n",
        "    inputs, input_mask)\n",
        "_, preds = torch.max(outputs, 1)  # ラベルを予測\n",
        "\n",
        "\n",
        "index = 7  # 出力させたいデータ\n",
        "html_output = mk_html(index, ts_ds, preds, normlized_weights_1, normlized_weights_2)  # HTML作成\n",
        "HTML(html_output)  # HTML形式で出力"
      ],
      "metadata": {
        "id": "w3C0zSDwS5tU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "outputId": "02880582-3786-4031-970b-ac18a56fbb08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "正解ラベル：Positive<br>推論ラベル：Positive<br><br>[TransformerBlockの1段目のAttentionを可視化]<br><span style=\"background-color: #FFFDFD\"> [CLS]</span><span style=\"background-color: #FFF6F6\"> i</span><span style=\"background-color: #FFBBBB\"> felt</span><span style=\"background-color: #FFF1F1\"> this</span><span style=\"background-color: #FFFDFD\"> film</span><span style=\"background-color: #FFFEFE\"> did</span><span style=\"background-color: #FFFDFD\"> have</span><span style=\"background-color: #FF6D6D\"> many</span><span style=\"background-color: #FFFDFD\"> good</span><span style=\"background-color: #FFF4F4\"> qualities</span><span style=\"background-color: #FFFDFD\"> .</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFFEFE\"> cinematography</span><span style=\"background-color: #FFFCFC\"> was</span><span style=\"background-color: #FFFCFC\"> certainly</span><span style=\"background-color: #FFFCFC\"> different</span><span style=\"background-color: #FFEEEE\"> exposing</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFFEFE\"> stage</span><span style=\"background-color: #FFE7E7\"> aspect</span><span style=\"background-color: #FFFEFE\"> of</span><span style=\"background-color: #FFFDFD\"> the</span><span style=\"background-color: #FFD9D9\"> set</span><span style=\"background-color: #FFFEFE\"> and</span><span style=\"background-color: #FFF0F0\"> story</span><span style=\"background-color: #FFFDFD\"> .</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFFEFE\"> original</span><span style=\"background-color: #FFFEFE\"> characters</span><span style=\"background-color: #FFFEFE\"> as</span><span style=\"background-color: #FFFDFD\"> actors</span><span style=\"background-color: #FFFBFB\"> was</span><span style=\"background-color: #FFFCFC\"> certainly</span><span style=\"background-color: #FFFDFD\"> an</span><span style=\"background-color: #FFFEFE\"> achievement</span><span style=\"background-color: #FFFEFE\"> and</span><span style=\"background-color: #FFF7F7\"> i</span><span style=\"background-color: #FFCACA\"> felt</span><span style=\"background-color: #FFFDFD\"> most</span><span style=\"background-color: #FFFDFD\"> played</span><span style=\"background-color: #FFFEFE\"> quite</span><span style=\"background-color: #FFE2E2\"> convincing</span><span style=\"background-color: #FFD9D9\"> ##ly</span><span style=\"background-color: #FFFAFA\"> ,</span><span style=\"background-color: #FFFEFE\"> of</span><span style=\"background-color: #FFFEFE\"> course</span><span style=\"background-color: #FFFDFD\"> they</span><span style=\"background-color: #FFFEFE\"> are</span><span style=\"background-color: #FFFEFE\"> playing</span><span style=\"background-color: #FFFDFD\"> themselves</span><span style=\"background-color: #FFFBFB\"> ,</span><span style=\"background-color: #FFFEFE\"> but</span><span style=\"background-color: #FFFEFE\"> definitely</span><span style=\"background-color: #FFFEFE\"> unique</span><span style=\"background-color: #FFFDFD\"> .</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFFEFE\"> cultural</span><span style=\"background-color: #FFF2F2\"> aspects</span><span style=\"background-color: #FFFEFE\"> may</span><span style=\"background-color: #FFFCFC\"> leave</span><span style=\"background-color: #FF0000\"> many</span><span style=\"background-color: #FFF5F5\"> disappointed</span><span style=\"background-color: #FFFEFE\"> as</span><span style=\"background-color: #FFD9D9\"> a</span><span style=\"background-color: #FFFAFA\"> familiarity</span><span style=\"background-color: #FFF9F9\"> with</span><span style=\"background-color: #FFFDFD\"> the</span><span style=\"background-color: #FFFEFE\"> chinese</span><span style=\"background-color: #FFFEFE\"> and</span><span style=\"background-color: #FFFEFE\"> oriental</span><span style=\"background-color: #FFF7F7\"> culture</span><span style=\"background-color: #FFFEFE\"> will</span><span style=\"background-color: #FFF9F9\"> answer</span><span style=\"background-color: #FFDADA\"> a</span><span style=\"background-color: #FFFDFD\"> lot</span><span style=\"background-color: #FFFEFE\"> of</span><span style=\"background-color: #FFFBFB\"> questions</span><span style=\"background-color: #FFF2F2\"> regarding</span><span style=\"background-color: #FFF9F9\"> parent</span><span style=\"background-color: #FFF8F8\"> child</span><span style=\"background-color: #FFE5E5\"> relationships</span><span style=\"background-color: #FFFEFE\"> and</span><span style=\"background-color: #FFFDFD\"> the</span><span style=\"background-color: #FFFEFE\"> stigma</span><span style=\"background-color: #FFFDFD\"> that</span><span style=\"background-color: #FFFCFC\"> goes</span><span style=\"background-color: #FFF9F9\"> with</span><span style=\"background-color: #FFF8F8\"> any</span><span style=\"background-color: #FF8282\"> drug</span><span style=\"background-color: #FFE4E4\"> use</span><span style=\"background-color: #FFFCFC\"> .</span><span style=\"background-color: #FFF4F4\"> i</span><span style=\"background-color: #FFFEFE\"> found</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFEFEF\"> jia</span><span style=\"background-color: #FFF9F9\"> hong</span><span style=\"background-color: #FFFEFE\"> ##sh</span><span style=\"background-color: #FFFEFE\"> ##eng</span><span style=\"background-color: #FFECEC\"> story</span><span style=\"background-color: #FFFEFE\"> interesting</span><span style=\"background-color: #FFFDFD\"> .</span><span style=\"background-color: #FFFAFA\"> on</span><span style=\"background-color: #FFDEDE\"> a</span><span style=\"background-color: #FFEFEF\"> down</span><span style=\"background-color: #FFFBFB\"> note</span><span style=\"background-color: #FFFAFA\"> ,</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFEBEB\"> story</span><span style=\"background-color: #FFFBFB\"> is</span><span style=\"background-color: #FFFCFC\"> in</span><span style=\"background-color: #FFFBFB\"> beijing</span><span style=\"background-color: #FFFEFE\"> and</span><span style=\"background-color: #FFF5F5\"> some</span><span style=\"background-color: #FFFEFE\"> of</span><span style=\"background-color: #FFFDFD\"> the</span><span style=\"background-color: #FFFCFC\"> fashion</span><span style=\"background-color: #FFFEFE\"> and</span><span style=\"background-color: #FFF9F9\"> music</span><span style=\"background-color: #FFFEFE\"> re</span><span style=\"background-color: #FFFCFC\"> ##ek</span><span style=\"background-color: #FFFEFE\"> of</span><span style=\"background-color: #FFFBFB\"> early</span><span style=\"background-color: #FFFAFA\"> 90s</span><span style=\"background-color: #FFFAFA\"> even</span><span style=\"background-color: #FFFDFD\"> though</span><span style=\"background-color: #FFE8E8\"> this</span><span style=\"background-color: #FFFAFA\"> was</span><span style=\"background-color: #FFBABA\"> made</span><span style=\"background-color: #FFFCFC\"> in</span><span style=\"background-color: #FFF7F7\"> 2001</span><span style=\"background-color: #FFF7F7\"> ,</span><span style=\"background-color: #FFF6F6\"> so</span><span style=\"background-color: #FFFCFC\"> it</span><span style=\"background-color: #FFC2C2\"> s</span><span style=\"background-color: #FFFEFE\"> really</span><span style=\"background-color: #FFFDFD\"> che</span><span style=\"background-color: #FFFDFD\"> ##es</span><span style=\"background-color: #FFFEFE\"> ##y</span><span style=\"background-color: #FFFAFA\"> sometimes</span><span style=\"background-color: #FFFDFD\"> the</span><span style=\"background-color: #FFF7F7\"> beatles</span><span style=\"background-color: #FFF9F9\"> crap</span><span style=\"background-color: #FFF7F7\"> ,</span><span style=\"background-color: #FFFDFD\"> etc</span><span style=\"background-color: #FFFCFC\"> .</span><span style=\"background-color: #FFFDFD\"> whatever</span><span style=\"background-color: #FFF6F6\"> ,</span><span style=\"background-color: #FFFAFA\"> not</span><span style=\"background-color: #FFCCCC\"> a</span><span style=\"background-color: #FFFEFE\"> top</span><span style=\"background-color: #FFBBBB\"> ten</span><span style=\"background-color: #FFFCFC\"> or</span><span style=\"background-color: #FFF7F7\"> twenty</span><span style=\"background-color: #FFFEFE\"> but</span><span style=\"background-color: #FFEFEF\"> if</span><span style=\"background-color: #FFFCFC\"> it</span><span style=\"background-color: #FFCFCF\"> s</span><span style=\"background-color: #FFF9F9\"> on</span><span style=\"background-color: #FFFDFD\"> the</span><span style=\"background-color: #FFFAFA\"> television</span><span style=\"background-color: #FFF3F3\"> ,</span><span style=\"background-color: #FFECEC\"> check</span><span style=\"background-color: #FFFBFB\"> it</span><span style=\"background-color: #FFF3F3\"> out</span><span style=\"background-color: #FFFAFA\"> .</span><span style=\"background-color: #FFFEFE\"> [SEP]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><br><br>[TransformerBlockの1段目のAttentionを可視化]<br><span style=\"background-color: #FFFEFE\"> [CLS]</span><span style=\"background-color: #FFFEFE\"> i</span><span style=\"background-color: #FFFEFE\"> felt</span><span style=\"background-color: #FFF3F3\"> this</span><span style=\"background-color: #FFFCFC\"> film</span><span style=\"background-color: #FFFEFE\"> did</span><span style=\"background-color: #FFFEFE\"> have</span><span style=\"background-color: #FFFEFE\"> many</span><span style=\"background-color: #FFFEFE\"> good</span><span style=\"background-color: #FFFEFE\"> qualities</span><span style=\"background-color: #FFFEFE\"> .</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFFBFB\"> cinematography</span><span style=\"background-color: #FFFEFE\"> was</span><span style=\"background-color: #FFFEFE\"> certainly</span><span style=\"background-color: #FFFEFE\"> different</span><span style=\"background-color: #FFFEFE\"> exposing</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFFEFE\"> stage</span><span style=\"background-color: #FFFEFE\"> aspect</span><span style=\"background-color: #FFFEFE\"> of</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFFEFE\"> set</span><span style=\"background-color: #FFFCFC\"> and</span><span style=\"background-color: #FFFEFE\"> story</span><span style=\"background-color: #FFFEFE\"> .</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFFAFA\"> original</span><span style=\"background-color: #FFFBFB\"> characters</span><span style=\"background-color: #FFFEFE\"> as</span><span style=\"background-color: #FFFEFE\"> actors</span><span style=\"background-color: #FFFEFE\"> was</span><span style=\"background-color: #FFFEFE\"> certainly</span><span style=\"background-color: #FFFBFB\"> an</span><span style=\"background-color: #FFFDFD\"> achievement</span><span style=\"background-color: #FFF8F8\"> and</span><span style=\"background-color: #FFFEFE\"> i</span><span style=\"background-color: #FFFEFE\"> felt</span><span style=\"background-color: #FFFEFE\"> most</span><span style=\"background-color: #FFFEFE\"> played</span><span style=\"background-color: #FFFDFD\"> quite</span><span style=\"background-color: #FFFEFE\"> convincing</span><span style=\"background-color: #FFFBFB\"> ##ly</span><span style=\"background-color: #FFFEFE\"> ,</span><span style=\"background-color: #FFFEFE\"> of</span><span style=\"background-color: #FFFDFD\"> course</span><span style=\"background-color: #FFFEFE\"> they</span><span style=\"background-color: #FFFEFE\"> are</span><span style=\"background-color: #FFFEFE\"> playing</span><span style=\"background-color: #FFFEFE\"> themselves</span><span style=\"background-color: #FFFEFE\"> ,</span><span style=\"background-color: #FFFEFE\"> but</span><span style=\"background-color: #FFF9F9\"> definitely</span><span style=\"background-color: #FFF9F9\"> unique</span><span style=\"background-color: #FFFEFE\"> .</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFFEFE\"> cultural</span><span style=\"background-color: #FFFEFE\"> aspects</span><span style=\"background-color: #FFF7F7\"> may</span><span style=\"background-color: #FFFEFE\"> leave</span><span style=\"background-color: #FFFEFE\"> many</span><span style=\"background-color: #FFFEFE\"> disappointed</span><span style=\"background-color: #FFFEFE\"> as</span><span style=\"background-color: #FFFEFE\"> a</span><span style=\"background-color: #FFFEFE\"> familiarity</span><span style=\"background-color: #FFFEFE\"> with</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFFEFE\"> chinese</span><span style=\"background-color: #FFFCFC\"> and</span><span style=\"background-color: #FFFEFE\"> oriental</span><span style=\"background-color: #FFFEFE\"> culture</span><span style=\"background-color: #FFFEFE\"> will</span><span style=\"background-color: #FFFEFE\"> answer</span><span style=\"background-color: #FFFEFE\"> a</span><span style=\"background-color: #FFFEFE\"> lot</span><span style=\"background-color: #FFFEFE\"> of</span><span style=\"background-color: #FFFEFE\"> questions</span><span style=\"background-color: #FFFEFE\"> regarding</span><span style=\"background-color: #FFFEFE\"> parent</span><span style=\"background-color: #FFFEFE\"> child</span><span style=\"background-color: #FFFEFE\"> relationships</span><span style=\"background-color: #FFFBFB\"> and</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFFEFE\"> stigma</span><span style=\"background-color: #FFFEFE\"> that</span><span style=\"background-color: #FFFEFE\"> goes</span><span style=\"background-color: #FFFEFE\"> with</span><span style=\"background-color: #FFFEFE\"> any</span><span style=\"background-color: #FFFEFE\"> drug</span><span style=\"background-color: #FFFAFA\"> use</span><span style=\"background-color: #FFFEFE\"> .</span><span style=\"background-color: #FFFEFE\"> i</span><span style=\"background-color: #FFFEFE\"> found</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFFEFE\"> jia</span><span style=\"background-color: #FFFEFE\"> hong</span><span style=\"background-color: #FFFEFE\"> ##sh</span><span style=\"background-color: #FFFBFB\"> ##eng</span><span style=\"background-color: #FFFEFE\"> story</span><span style=\"background-color: #FFFAFA\"> interesting</span><span style=\"background-color: #FFFEFE\"> .</span><span style=\"background-color: #FFFAFA\"> on</span><span style=\"background-color: #FFFEFE\"> a</span><span style=\"background-color: #FFFEFE\"> down</span><span style=\"background-color: #FFFEFE\"> note</span><span style=\"background-color: #FFFEFE\"> ,</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFFEFE\"> story</span><span style=\"background-color: #FFFEFE\"> is</span><span style=\"background-color: #FFFEFE\"> in</span><span style=\"background-color: #FFFCFC\"> beijing</span><span style=\"background-color: #FFFDFD\"> and</span><span style=\"background-color: #FFFEFE\"> some</span><span style=\"background-color: #FFFEFE\"> of</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFFEFE\"> fashion</span><span style=\"background-color: #FFFBFB\"> and</span><span style=\"background-color: #FFF5F5\"> music</span><span style=\"background-color: #FFFEFE\"> re</span><span style=\"background-color: #FFFEFE\"> ##ek</span><span style=\"background-color: #FFFEFE\"> of</span><span style=\"background-color: #FFFEFE\"> early</span><span style=\"background-color: #FFFEFE\"> 90s</span><span style=\"background-color: #FFF2F2\"> even</span><span style=\"background-color: #FFFEFE\"> though</span><span style=\"background-color: #FFF8F8\"> this</span><span style=\"background-color: #FFFEFE\"> was</span><span style=\"background-color: #FFFEFE\"> made</span><span style=\"background-color: #FFFDFD\"> in</span><span style=\"background-color: #FFFEFE\"> 2001</span><span style=\"background-color: #FFFEFE\"> ,</span><span style=\"background-color: #FFFEFE\"> so</span><span style=\"background-color: #FFFEFE\"> it</span><span style=\"background-color: #FFFEFE\"> s</span><span style=\"background-color: #FFFEFE\"> really</span><span style=\"background-color: #FFFEFE\"> che</span><span style=\"background-color: #FFFDFD\"> ##es</span><span style=\"background-color: #FFFEFE\"> ##y</span><span style=\"background-color: #FFFDFD\"> sometimes</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFFEFE\"> beatles</span><span style=\"background-color: #FFFEFE\"> crap</span><span style=\"background-color: #FFFEFE\"> ,</span><span style=\"background-color: #FFFEFE\"> etc</span><span style=\"background-color: #FFFEFE\"> .</span><span style=\"background-color: #FFFDFD\"> whatever</span><span style=\"background-color: #FFFEFE\"> ,</span><span style=\"background-color: #FFFEFE\"> not</span><span style=\"background-color: #FFFEFE\"> a</span><span style=\"background-color: #FF0000\"> top</span><span style=\"background-color: #FFFEFE\"> ten</span><span style=\"background-color: #FFFEFE\"> or</span><span style=\"background-color: #FFFEFE\"> twenty</span><span style=\"background-color: #FFFEFE\"> but</span><span style=\"background-color: #FFFEFE\"> if</span><span style=\"background-color: #FFFEFE\"> it</span><span style=\"background-color: #FFFEFE\"> s</span><span style=\"background-color: #FFF5F5\"> on</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFFBFB\"> television</span><span style=\"background-color: #FFFEFE\"> ,</span><span style=\"background-color: #FFF7F7\"> check</span><span style=\"background-color: #FFFEFE\"> it</span><span style=\"background-color: #FFFEFE\"> out</span><span style=\"background-color: #FFFEFE\"> .</span><span style=\"background-color: #FFFEFE\"> [SEP]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><span style=\"background-color: #FFFEFE\"> [PAD]</span><br><br>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "以上"
      ],
      "metadata": {
        "id": "2MbMYx4HknEw"
      }
    }
  ]
}